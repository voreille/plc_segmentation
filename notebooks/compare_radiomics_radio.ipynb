{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (accuracy_score, recall_score, precision_score,\n",
    "                             roc_auc_score, confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedKFold,\n",
    "                                     train_test_split)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_df = pd.read_csv(\"/home/valentin/python_wkspce/plc_segmentation/data/clinical_info_updated.csv\").set_index(\"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = clinical_df.index\n",
    "ids = [\n",
    "    i for i in ids if i not in\n",
    "    [\"PatientLC_71\", \"PatientLC_21\", \"PatientLC_63\", \"PatientLC_72\"]\n",
    "]\n",
    "clinical_df = clinical_df.loc[ids, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df[\"PET_lymphangitis_Visual_analysis\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_id(df, plc_status=0, missclassified=True, criterion=\"thickening\"):\n",
    "    crit = {\n",
    "        \"thickening\": \"Peri bronchovascular thickening\",\n",
    "        \"pet\": \"PET_lymphangitis_Visual_analysis\",\n",
    "    }\n",
    "    if missclassified:\n",
    "        return ((df[\"plc_status\"] == plc_status)\n",
    "                & (~df[crit[criterion]].isna())\n",
    "                & (df.plc_status != df[crit[criterion]]) & (df.is_chuv == 1))\n",
    "    else:\n",
    "        return ((df[\"plc_status\"] == plc_status)\n",
    "                & (~df[crit[criterion]].isna())\n",
    "                & (df.plc_status == df[crit[criterion]])\n",
    "                & (df.is_chuv == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df[select_id(clinical_df, plc_status=0, missclassified=True, criterion=\"pet\")].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of ids_test: 2\n",
      "length of ids_test: 20\n",
      "length of ids_test: 40\n",
      "length of ids_test: 40\n"
     ]
    }
   ],
   "source": [
    "ids_test = list(\n",
    "    np.random.choice(\n",
    "        clinical_df[select_id(\n",
    "            clinical_df,\n",
    "            plc_status=0,\n",
    "            criterion=\"pet\",\n",
    "        )].index,\n",
    "        size=18,\n",
    "        replace=False,\n",
    "    ))\n",
    "print(f\"length of ids_test: {len(ids_test)}\")\n",
    "ids_test.extend(\n",
    "    list(\n",
    "        np.random.choice(\n",
    "            clinical_df[select_id(\n",
    "                clinical_df,\n",
    "                plc_status=0,\n",
    "                missclassified=False,\n",
    "                criterion=\"pet\",\n",
    "            )].index,\n",
    "            size=2,\n",
    "            replace=False,\n",
    "        )))\n",
    "print(f\"length of ids_test: {len(ids_test)}\")\n",
    "ids_test.extend(\n",
    "    list(\n",
    "        np.random.choice(clinical_df[select_id(clinical_df,\n",
    "                                               plc_status=1)].index,\n",
    "                         size=12,\n",
    "                         replace=False)))\n",
    "ids_test.extend(\n",
    "    list(\n",
    "        np.random.choice(clinical_df[select_id(clinical_df,\n",
    "                                               plc_status=1,\n",
    "                                               missclassified=False)].index,\n",
    "                         size=8,\n",
    "                         replace=False)))\n",
    "\n",
    "print(f\"length of ids_test: {len(set(ids_test))}\")\n",
    "yo = set(ids_test) - set(ids).intersection(ids_test)\n",
    "ids_test = list(set(ids).intersection(ids_test))\n",
    "print(f\"length of ids_test: {len(ids_test)}\")\n",
    "ids_train = list(set(ids) - set(ids_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(ids).intersection(ids_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_df[(clinical_df.plc_status == 1) & (\n",
    "    clinical_df.plc_status != clinical_df[\"PET_lymphangitis_Visual_analysis\"])\n",
    "            & (clinical_df.is_chuv == 1) &\n",
    "            (~clinical_df[\"PET_lymphangitis_Visual_analysis\"].isna())].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = clinical_df.loc[ids_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69125"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_test[\"plc_status\"], df_test[\"LymphangitisCT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_score(df, y_true, y_pred, y_score, pos_label=1, neg_label=0):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    specificity = tn / (tn + fp)\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "    return df.append(\n",
    "        {\n",
    "            'roc_auc': roc_auc,\n",
    "            'specificity': specificity,\n",
    "            'sensitivity': sensitivity,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'npv': npv,\n",
    "        },\n",
    "        ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['plc_status', 'patient_age', 'patient_sex', 'SUVmax_lesion',\n",
       "       'SUVmean_lesion', 'MTV', 'TLG', 'PET_lymphangitis_Visual_analysis',\n",
       "       'Peri bronchovascular thickening', 'LymphangitisCT', 'pT', 'pN', 'M',\n",
       "       'stage', 'pathologic type', 'is_chuv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(d):\n",
    "    for key, item in d.items():\n",
    "        print(f\"{key}: {item[0]:0.2f} ({item[1]:0.2f} - {item[2]:0.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_pred(y_true, y_pred, y_score, bootstraps=1000):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    assert len(y_true) == len(y_score)\n",
    "\n",
    "    score = pd.DataFrame()\n",
    "    for _ in range(bootstraps):\n",
    "        y_true_resampled, y_pred_resampled, y_score_resampled = resample(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            y_score,\n",
    "            replace=True,\n",
    "            n_samples=len(y_true),\n",
    "            stratify=y_true,\n",
    "        )\n",
    "\n",
    "        score = append_score(score,\n",
    "                             y_true_resampled,\n",
    "                             y_pred_resampled,\n",
    "                             y_score_resampled,\n",
    "                             pos_label=1)\n",
    "\n",
    "    ic_score = {\n",
    "        'roc_auc': [],\n",
    "        'specificity': [],\n",
    "        'sensitivity': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'npv': []\n",
    "    }\n",
    "\n",
    "    for col in score.columns:\n",
    "        ic_score[col].append(np.mean(score[col].values))\n",
    "        ic_score[col].append(np.percentile(score[col].values, 2.5))\n",
    "        ic_score[col].append(np.percentile(score[col].values, 97.5))\n",
    "    return ic_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['plc_status', 'patient_age', 'patient_sex', 'SUVmax_lesion',\n",
       "       'SUVmean_lesion', 'MTV', 'TLG', 'PET_lymphangitis_Visual_analysis',\n",
       "       'Peri bronchovascular thickening', 'LymphangitisCT', 'pT', 'pN', 'M',\n",
       "       'stage', 'pathologic type', 'is_chuv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = df_test[''].values\n",
    "# X_test = df_test['Peri bronchovascular thickening'].values\n",
    "X_test = df_test['PET_lymphangitis_Visual_analysis'].values\n",
    "y_test = df_test.plc_status.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f9ac722e926f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2d252702771e>\u001b[0m in \u001b[0;36mbootstrap_pred\u001b[0;34m(y_true, y_pred, y_score, bootstraps)\u001b[0m\n\u001b[1;32m     18\u001b[0m                              \u001b[0my_pred_resampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                              \u001b[0my_score_resampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                              pos_label=1)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     ic_score = {\n",
      "\u001b[0;32m<ipython-input-13-b741cac0e593>\u001b[0m in \u001b[0;36mappend_score\u001b[0;34m(df, y_true, y_pred, y_score, pos_label, neg_label)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnpv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     return df.append(\n\u001b[1;32m     10\u001b[0m         {\n",
      "\u001b[0;32m~/python_wkspce/plc_segmentation/env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_wkspce/plc_segmentation/env/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[0;32m~/python_wkspce/plc_segmentation/env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_wkspce/plc_segmentation/env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 721\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_wkspce/plc_segmentation/env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n\u001b[0;32m--> 106\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m             )\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print_results(bootstrap_pred(y_test, (X_test != 0), X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    col_to_drop = [c for c in df.columns if c.startswith('diagnostics')]\n",
    "    col_to_drop.extend(\n",
    "        [c for c in df.columns if 'glcm' in c and 'original' not in c])\n",
    "    col_to_drop.extend([c for c in df.columns if 'RootMeanSquared' in c])\n",
    "    col_to_drop.extend(\n",
    "        [c for c in df.columns if '_MeanAbsoluteDeviation' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_Median' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_Range' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_InterquartileRange' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if 'Percentile' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_RootMeanSquared' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_TotalEnergy' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if '_Uniformity' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if 'wavelet' in c])\n",
    "    col_to_drop.extend([c for c in df.columns if 'shape' in c])\n",
    "\n",
    "    return df.drop(col_to_drop, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_features, path_to_outcomes):\n",
    "    df = pd.read_csv(path_to_features)\n",
    "    df = df[~df.patient_id.isin(\n",
    "        [\"PatientLC_71\", \"PatientLC_21\", \"PatientLC_63\", \"PatientLC_72\"])]\n",
    "    clinical_df = pd.read_csv(path_to_outcomes).set_index(\"patient_id\")\n",
    "    df[\"plc_status\"] = df[\"patient_id\"].map(\n",
    "        lambda x: clinical_df.loc[x, \"plc_status\"])\n",
    "\n",
    "    df[\"is_chuv\"] = df[\"patient_id\"].map(\n",
    "        lambda x: clinical_df.loc[x, \"is_chuv\"])\n",
    "\n",
    "    df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "    df = clean_df(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_formatted_data(\n",
    "    df,\n",
    "    modality=\"CT\",\n",
    "    voi=\"GTV_L\",\n",
    "    ids_train=None,\n",
    "    ids_test=None,\n",
    "):\n",
    "    df = df[(df[\"modality\"] == modality) & (df[\"voi\"] == voi)]\n",
    "    ids = df[\"patient_id\"].values\n",
    "    df = df.set_index(\"patient_id\")\n",
    "\n",
    "    outcomes_df = df[\"plc_status\"]\n",
    "    df = df.drop([\"plc_status\", \"voi\", \"modality\"], axis=1)\n",
    "\n",
    "    X_train = df.loc[ids_train, :].values\n",
    "    X_test = df.loc[ids_test, :].values\n",
    "    feature_names = df.columns\n",
    "\n",
    "    y_train = outcomes_df.loc[ids_train].values\n",
    "    y_test = outcomes_df.loc[ids_test].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch():\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    clf_lr = LogisticRegression(penalty=\"none\", solver='sag', max_iter=1000)\n",
    "    clf_rf = RandomForestClassifier()\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('normalization', scaler),\n",
    "        ('feature_selection', None),\n",
    "        ('classifier', None),\n",
    "    ])\n",
    "\n",
    "    F_OPTIONS = [1, 2, 3, 5]\n",
    "    K_OPTIONS = [k for k in range(1, 11)]\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'feature_selection': [SelectKBest(f_classif)],\n",
    "            'feature_selection__k': F_OPTIONS,\n",
    "            'classifier': [clf_rf],\n",
    "            'classifier__n_estimators': [100, 150]\n",
    "        },\n",
    "        {\n",
    "            'feature_selection': [SelectKBest(f_classif)],\n",
    "            'feature_selection__k': F_OPTIONS,\n",
    "            'classifier': [clf_lr],\n",
    "        },\n",
    "        {\n",
    "            'feature_selection': [PCA()],\n",
    "            'feature_selection__n_components': K_OPTIONS,\n",
    "            'classifier': [clf_lr],\n",
    "        },\n",
    "        {\n",
    "            'feature_selection': [PCA()],\n",
    "            'feature_selection__n_components': K_OPTIONS,\n",
    "            'classifier': [clf_rf],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=StratifiedKFold(),\n",
    "                        n_jobs=23,\n",
    "                        refit=True,\n",
    "                        verbose=1,\n",
    "                        scoring=\"roc_auc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = get_gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = load_data(\n",
    "    \"../data/processed/radiomics/extracted_features.csv\",\n",
    "    # \"../data/processed/radiomics/extracted_features.csv\",\n",
    "    \"../data/clinical_info_updated.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names = get_formatted_data(df, modality=\"PT\", voi=\"GTV_L\",ids_test=ids_test, ids_train=ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 77)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('normalization', StandardScaler()),\n",
       "                                       ('feature_selection', None),\n",
       "                                       ('classifier', None)]),\n",
       "             n_jobs=23,\n",
       "             param_grid=[{'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__n_estimators': [100, 150],\n",
       "                          'feature_selection': [SelectKBest()],\n",
       "                          'feature_selection__k': [1, 2,...\n",
       "                          'feature_selection__k': [1, 2, 3, 5]},\n",
       "                         {'classifier': [LogisticRegression(max_iter=1000,\n",
       "                                                            penalty='none',\n",
       "                                                            solver='sag')],\n",
       "                          'feature_selection': [PCA()],\n",
       "                          'feature_selection__n_components': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'feature_selection': [PCA(n_components=10)],\n",
       "                          'feature_selection__n_components': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9, 10]}],\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('normalization', StandardScaler()),\n",
       "                ('feature_selection', PCA(n_components=10)),\n",
       "                ('classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.82 (0.66 - 0.94)\n",
      "specificity: 0.65 (0.45 - 0.85)\n",
      "sensitivity: 0.90 (0.75 - 1.00)\n",
      "accuracy: 0.78 (0.65 - 0.90)\n",
      "precision: 0.73 (0.61 - 0.86)\n",
      "npv: 0.87 (0.73 - 1.00)\n"
     ]
    }
   ],
   "source": [
    "print_results(bootstrap_pred(y_test, search.predict(X_test), search.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, feature_names = get_formatted_data(df, modality=\"PT\", voi=\"GTV_L\",ids_test=ids_test, ids_train=ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "suvmax_test = X_test[:, feature_names == \"original_firstorder_Mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7387198155221634"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(suvmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc: 0.87 (0.73 - 0.96)\n",
      "specificity: 0.90 (0.75 - 1.00)\n",
      "sensitivity: 0.70 (0.50 - 0.85)\n",
      "accuracy: 0.80 (0.68 - 0.90)\n",
      "precision: 0.88 (0.73 - 1.00)\n",
      "npv: 0.76 (0.63 - 0.87)\n"
     ]
    }
   ],
   "source": [
    "print_results(bootstrap_pred(y_test, (suvmax_test>0.7), suvmax_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26794336849f69f1a455c7b9076cea9e2673f8b3db6968d6e62389984b0c1cbc"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('env': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
