{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(noise=0.352, random_state=1, n_samples=150)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0], y=X[:, 1], hue=y, marker=\"o\", s=25, edgecolor=\"k\", legend=False\n",
    ").set_title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = [\n",
    "    {\"kernel\": [\"linear\"]},\n",
    "    {\"kernel\": [\"poly\"], \"degree\": [2, 3]},\n",
    "    {\"kernel\": [\"rbf\"]},\n",
    "]\n",
    "\n",
    "svc = SVC(random_state=0)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=0)\n",
    "\n",
    "search = GridSearchCV(estimator=svc, param_grid=param_grid, scoring=\"roc_auc\", cv=cv)\n",
    "search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(search.cv_results_)\n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "results_df = results_df.set_index(results_df[\"params\"].apply(\n",
    "    lambda x: \"_\".join(str(val) for val in x.values()))).rename_axis(\"kernel\")\n",
    "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df of model scores ordered by performance\n",
    "model_scores = results_df.filter(regex=r\"split\\d*_test_score\")\n",
    "\n",
    "# plot 30 examples of dependency between cv fold and AUC scores\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    data=model_scores.transpose().iloc[:30],\n",
    "    dashes=False,\n",
    "    palette=\"Set1\",\n",
    "    marker=\"o\",\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"CV test fold\", size=12, labelpad=10)\n",
    "ax.set_ylabel(\"Model AUC\", size=12)\n",
    "ax.tick_params(bottom=True, labelbottom=False)\n",
    "plt.show()\n",
    "\n",
    "# print correlation of AUC scores across folds\n",
    "print(f\"Correlation of models:\\n {model_scores.transpose().corr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected_std(differences, n_train, n_test):\n",
    "    \"\"\"Corrects standard deviation using Nadeau and Bengio's approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : ndarray of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected_std : float\n",
    "        Variance-corrected standard deviation of the set of differences.\n",
    "    \"\"\"\n",
    "    # kr = k times r, r times repeated k-fold crossvalidation,\n",
    "    # kr equals the number of times the model was evaluated\n",
    "    kr = len(differences)\n",
    "    corrected_var = np.var(differences, ddof=1) * (1 / kr + n_test / n_train)\n",
    "    corrected_std = np.sqrt(corrected_var)\n",
    "    return corrected_std\n",
    "\n",
    "\n",
    "def compute_corrected_ttest(differences, df, n_train, n_test):\n",
    "    \"\"\"Computes right-tailed paired t-test with corrected variance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : array-like of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    df : int\n",
    "        Degrees of freedom.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_stat : float\n",
    "        Variance-corrected t-statistic.\n",
    "    p_val : float\n",
    "        Variance-corrected p-value.\n",
    "    \"\"\"\n",
    "    mean = np.mean(differences)\n",
    "    std = corrected_std(differences, n_train, n_test)\n",
    "    t_stat = mean / std\n",
    "    p_val = t.sf(np.abs(t_stat), df)  # right-tailed t-test\n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_scores = model_scores.iloc[0].values  # scores of the best model\n",
    "model_2_scores = model_scores.iloc[1].values  # scores of the second-best model\n",
    "\n",
    "differences = model_1_scores - model_2_scores\n",
    "\n",
    "n = differences.shape[0]  # number of test sets\n",
    "df = n - 1\n",
    "n_train = len(list(cv.split(X, y))[0][0])\n",
    "n_test = len(list(cv.split(X, y))[0][1])\n",
    "\n",
    "t_stat, p_val = compute_corrected_ttest(differences, df, n_train, n_test)\n",
    "print(f\"Corrected t-value: {t_stat:.3f}\\nCorrected p-value: {p_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat_uncorrected = np.mean(differences) / np.sqrt(np.var(differences, ddof=1) / n)\n",
    "p_val_uncorrected = t.sf(np.abs(t_stat_uncorrected), df)\n",
    "\n",
    "print(\n",
    "    f\"Uncorrected t-value: {t_stat_uncorrected:.3f}\\n\"\n",
    "    f\"Uncorrected p-value: {p_val_uncorrected:.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26794336849f69f1a455c7b9076cea9e2673f8b3db6968d6e62389984b0c1cbc"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('env': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
